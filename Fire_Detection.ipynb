{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meghanareddy712/CS384-Projects/blob/main/Fire_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv9rX51RRWpP",
        "outputId": "96bea0f4-39d2-4d14-ea4d-6a61514f32b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 5.57 ms (started: 2022-04-23 12:50:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpYNiJ8-Rh1D"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVWS9Mh3Rxdc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# to read the images\n",
        "from skimage.io import imread \n",
        "import tensorflow as tf\n",
        "#groups layers into an object with training and inference features\n",
        "from tensorflow.keras import models \n",
        "from tensorflow.keras import layers \n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joTznapvR2-q"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/Design_Lab_Fire_Detection/dataset/fire/ds.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThNpMDNdRlrF"
      },
      "outputs": [],
      "source": [
        "DATADIR = '/content/ds'\n",
        "CATEGORIES = ['fire','smoke','neutral']\n",
        "\n",
        "\n",
        "#iterete\n",
        "for category in CATEGORIES:\n",
        "  print(category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edlsV257Rseg"
      },
      "outputs": [],
      "source": [
        "#iterete\n",
        "images = []\n",
        "test = []\n",
        "train = []\n",
        "train_label = []\n",
        "test_label = []\n",
        "run_test = []\n",
        "for category in CATEGORIES:\n",
        "  class_num = CATEGORIES.index(category) #Label the encoding\n",
        "  path = os.path.join(DATADIR,category) #os lib used to create path to use all\n",
        "  #print(path)\n",
        "  i = 0\n",
        "  n = len(os.listdir(path))\n",
        "  for img in os.listdir(path):\n",
        "      img_array = imread(os.path.join(path,img))\n",
        "      try:\n",
        "        img_resize = tf.image.resize(img_array,[250,250])\n",
        "        if img_resize.shape[-1]!=3:\n",
        "          continue\n",
        "        if i==1:\n",
        "          run_test.append(img_resize)\n",
        "        if i<(0.7*n):\n",
        "          train.append(img_resize)\n",
        "          train_label.append(class_num)\n",
        "        else:\n",
        "          test.append(img_resize)\n",
        "          test_label.append(class_num)\n",
        "        i += 1\n",
        "      except:\n",
        "        continue     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-8N5mx5ozXs"
      },
      "outputs": [],
      "source": [
        "img_resize[-1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D35NljSU4V5"
      },
      "outputs": [],
      "source": [
        "def plot_no_of_images(label):\n",
        "  unique,count = np.unique(label, return_counts=True)\n",
        "  print(unique,count)\n",
        "  x = CATEGORIES\n",
        "  y = count\n",
        "  plt.bar(x,y,color='g')\n",
        "\n",
        "  #plt.title('Gathered Data')\n",
        "  plt.xlabel('CATEGORIES')\n",
        "  plt.ylabel('Number of images')\n",
        "  for i in range(len(x)):\n",
        "    plt.text(i,y[i],y[i])\n",
        "\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plot_no_of_images(train_label)\n",
        "plt.title(\"Dataset gathered for training\")\n",
        "plt.subplot(1,2,2)\n",
        "plot_no_of_images(test_label)\n",
        "plt.title(\"Dataset gathered for testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-jD1i6ggeKo"
      },
      "outputs": [],
      "source": [
        "train_label = tf.one_hot(train_label,3) \n",
        "test_label = tf.one_hot(test_label,3)\n",
        "\n",
        "image_test = tf.convert_to_tensor(test)\n",
        "image_train = tf.convert_to_tensor(train)\n",
        "\n",
        "image_train = (image_train).numpy() #tensor to numpy\n",
        "image_test = (image_test).numpy()\n",
        "train_label = train_label.numpy()\n",
        "# Shuffling of data\n",
        "image_train,image_label = sklearn.utils.shuffle(image_train,train_label)\n",
        "\n",
        "image_test = tf.convert_to_tensor(image_test)\n",
        "image_train = tf.convert_to_tensor(image_train)\n",
        "image_label = tf.convert_to_tensor(image_label)\n",
        "run_test = tf.convert_to_tensor(run_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hc15HBEdIA-"
      },
      "outputs": [],
      "source": [
        "# image_train = (image_train/255).numpy() #tensor to numpy\n",
        "# image_test = (image_test/255).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Arrmpyfnp1"
      },
      "source": [
        "#CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuqJLXQIcRdP"
      },
      "outputs": [],
      "source": [
        " # create the model\n",
        " cnn = models.Sequential([\n",
        "     layers.Conv2D(filters=20, kernel_size=(3, 3),strides = 2, padding = 'same',activation='relu', input_shape=(250, 250, 3)), # in\n",
        "     layers.MaxPooling2D((2, 2),strides = 2,padding = 'same'),\n",
        "    \n",
        "     layers.Conv2D(filters=20, kernel_size=(3, 3),strides = 2,padding = 'same', activation='relu'),\n",
        "     layers.MaxPooling2D((2, 2),strides = 2,padding = 'same'),\n",
        "\n",
        "     layers.Conv2D(filters=20, kernel_size=(3, 3),strides = 2,padding = 'same', activation='relu'),\n",
        "     layers.MaxPooling2D((2, 2),strides = 2,padding = 'same'),\n",
        "    \n",
        "     layers.Flatten(),\n",
        "     layers.Dense(64, activation='relu'),\n",
        "    \n",
        "     layers.Dense(3, activation='softmax')# out\n",
        " ])\n",
        "\n",
        " # Compile the model\n",
        " cnn.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        " cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuqzKkedgUVb"
      },
      "outputs": [],
      "source": [
        " callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        " history = cnn.fit(x = image_train, \n",
        "                    y = image_label, \n",
        "                   epochs = 10,\n",
        "                   batch_size = 32,\n",
        "                   validation_data = (image_test,test_label), \n",
        "                   callbacks=[callback]\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4j5egh9iOLI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'],label = 'loss')\n",
        "plt.plot(history.history['val_loss'],label = 'val_loss')\n",
        "plt.title('Loss curve')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'],label = 'accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label = 'val_accuracy')\n",
        "plt.title('Accuracy curve')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cikQ0NYvwzD"
      },
      "outputs": [],
      "source": [
        "loss, acc = cnn.evaluate(image_test,test_label)\n",
        "print(f\"Training accuracy : {(acc*100):.2f} %\")\n",
        "print(f\"Training loss : {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4jBcVopfqw3"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrguUAKMfqNm"
      },
      "outputs": [],
      "source": [
        "# Creating model from pretrained model : EfficientNetB0\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "inputs = layers.Input(shape = (250, 250, 3), name = \"input_layer\")\n",
        "x = base_model(inputs, training = False)\n",
        "x = layers.GlobalAveragePooling2D(name = \"global_average_pooling_2D\")(x)\n",
        "outputs = layers.Dense(3, activation = \"softmax\", name = \"output_layer\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE8Oepo6iQqf"
      },
      "outputs": [],
      "source": [
        "#  Creating ModelCheckpoint callback\n",
        "checkpoint_path = \"modelCheckpoint.ckpt\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                                          save_weights_only = True,\n",
        "                                                          save_best_only = True,\n",
        "                                                          save_frequency = \"epoch\",\n",
        "                                                          verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2XiYQXgjE6V"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "initial_epoch = 5\n",
        "history = model.fit(image_train,\n",
        "                     image_label,\n",
        "                     epochs = initial_epoch,\n",
        "                     validation_data = (image_test, test_label),\n",
        "                     callbacks = [checkpoint_callback]) \n",
        "model.save(\"Fire_smoke_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ispk6l4Bjy8x"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning model\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layers.trainable = False\n",
        "\n",
        "# Recompile model\n",
        "model.compile(loss = \"categorical_crossentropy\", \n",
        "              optimizer = tf.keras.optimizers.Adam(lr = 0.0001),\n",
        "               metrics = [\"accuracy\"])\n",
        "\n",
        "fine_tune_epochs = initial_epoch + 5\n",
        "\n",
        "# Refit model\n",
        "history_fine = model.fit(image_train,\n",
        "                          image_label,\n",
        "                          epochs = fine_tune_epochs,\n",
        "                          validation_data = (image_test, test_label),\n",
        "                          initial_epoch = history.epoch[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUy2mRhGrUzw"
      },
      "outputs": [],
      "source": [
        "model.save(\"Fire_smoke_FineTuned\")\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7KryqwvGo06"
      },
      "outputs": [],
      "source": [
        "ypred = base_model.predict(image_test[1:])\n",
        "ypred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKu8fcjyQDCr"
      },
      "source": [
        "Visualize training results\n",
        "Create plots of loss and accuracy on the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_h02abEUCxj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-nMVgu1Xeuk"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(image_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCFncBkrfkJe"
      },
      "source": [
        "#TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W27O4YQWhijX"
      },
      "outputs": [],
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Design_Lab_Fire_Detection/Fire_smoke_FineTuned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtqlaXZFf5c-"
      },
      "outputs": [],
      "source": [
        "# Check its architecture\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYnoBpWJiOhx"
      },
      "outputs": [],
      "source": [
        "ypred = new_model.predict(run_test)\n",
        "ypred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZnGDOcypsEG"
      },
      "outputs": [],
      "source": [
        "ypred2 = new_model.predict(image_test)\n",
        "ypred2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfMysl3_gDGj"
      },
      "outputs": [],
      "source": [
        "# Evaluate the restored model\n",
        "loss, acc = new_model.evaluate(image_test, test_label, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Fire_Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}